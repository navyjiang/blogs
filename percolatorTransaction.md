
# percolator 事务协议
```
问题：

1. 如果在读取的单元上有锁，BackoffAndMaybeCleanupLock() 会等待直到该锁消除还是清除锁？ 如果等待会等待多久？如果被等的事务是遗留事务呢（这时如果不清除锁那就会一直等待呀）？ 感觉应该是先等待，超时后，则会清理这些锁。

2. 如果两个事务 A 和 B 几乎同时开始对单元a和单元b进行修改，几乎同时调用 prewrite，A 锁定了单元a，B 锁定了单元b，然后，A 试图锁定 b，失败，退出，B 试图锁定 a， 失败，也退出，两个事务都退出了，这样可能吗？

3. 伪代码34行 Prewrite 时，如果看到某单元上有任意时间戳的某个锁，会立即取消事务，那如果不读直接写的情况，什么时候清理遗留的锁呢？必须等到读的时候才能清理锁吗？是不是应该看到如果锁的时间戳在当前事务开始时间戳之前，就等待超时之后清除锁呢？

4. 论文 2.3 节最后，当R的Get()看到lock时，是 W 将会block直到lock释放吗？应该是 R 将会block吧？

5. 两个客户端在Bigtable的同一行上同时开启单行事务，会像锁一样两个客户端互斥吗？即会是只有一个客户端能开启单行事务而另一个客户端阻塞直到开启了单行事务的客户端提交吗？还是类似于乐观锁，允许同时开启事务，提交时才决定成败？

6. 在伪代码中，如果某个单元的prewrite失败，Commit()方法就直接退出了，没有清理前面成功执行prewrite单元的锁，为什么不清理后再退出呢？也许就应该先清理后退出，只是伪代码省略了与主线无关的细节？
```

为了实现分布式事务，percolator采用元数据的方式，给每个存储数据的单元（称为data）再附加两列元数据单元：lock和write，即每个percolator列对应三个Bigtable列，这三个Bigtable单元位于Bigtable的同一行。例如如果某个 percolator 的列为 c，那么在 Bigtable中的三列可表示为：c:data、c:lock、c:write。

此外，percolator 还依赖一个时间戳服务，称为“timestamp oracle”，timestamp oracle 为分布式事务提供严格递增的时间戳。每个事务需要向 timestamp oracle 两次获取时间戳，分别为事务开始时间戳 start_ts 和 事务提交时间戳 commit_ts。

## 写操作 Set()
对于写操作 Set()，调用该方法时只是把要写的值缓存起来，一直到事务提交的时候才最后把所有要写的值统一提交。多行分布式事务是利用 Bigtable 的单行事务实现的。

## 事务提交
### 第一阶段
提交的过程分两个阶段，第一个阶段叫 prewrite，在这一阶段，要做的事就是实际写入所有要写的数据（但不会暴露给其他事务）。具体做法把所有要写的数据拿过来依次处理，为每个要写入的数据值 c 开启一个单行事务以开始时间戳 start_ts 同时写入 c:lock 和 c:data。第一个被写入的数据称为 primary（primary可以任意选取），其他数据称为 secondary。这里提出 primary 的概念是为了处理失败的情况，在失败的情况下，如何利用单行事务以及 primary 保证分布式事务的完成，后面会讲到。在处理这些数据的时候，可能会遇到冲突，事务通过读取每个被写的单元的元数据（lock和write）来检查冲突。有两种情形的元数据显示事务遇到了冲突：

1. 一种是如果事务在write列看到了它的开始时间戳之后的由另一个事务写入的某个值（这表示另一个事务已经先于本事务提交了)，它就终止，这正是快照隔离级别所要保护的写写冲突；

2. 另一种是如果事务在lock列中看到由其他事务写入的任意时间戳的某个锁，它会终止（正好是本文问题2和问题3中的疑问，这点有待商榷？）。

如果上面两种冲突都没有，则在前面开启的单行事务中以开始时间戳 start_ts 同时写入lock和data。在lock位置写入的内容是primary数据所在的行列位置，这样根据任何一个数据的lock值可以找到primary数据的状态，而整个事务的状态依赖于primary数据的状态。

关于上面第 2 点，说的是伪代码描述的行为，我感觉在看到lock列中有其他事务写入的某个锁时，不应简单终止，还是应该执行 BackoffAndMaybeCleanupLock 操作，否则会发生本文问题2描述的问题。但这时如果发生清理回滚或前滚（见后面关于失败处理的部分）了其他事务还好，本事务可以继续进行；如果是等待其他事务先执行完并先提交了事务，这时又分两种情况：如果这个其他事务的提交时间戳小于本事务的开始时间戳，那么本事务也可以继续进行，否则，即这个其他事务的提交时间戳大于本事务的开始时间戳，那么会转化为第 1 点所述的写写冲突，本事务还是要终止。

### 第二阶段
如果每一个要写的数据值都在没有冲突的情况下顺利写入，那么事务可以继续提交，进入提交的第二阶段。在第二阶段的开始，客户端先从 timestamp oracle 获取一个提交时间戳 commit_ts，然后从 primary 开始，对每个数据按顺序做如下两步操作： 
1. 以 commit_ts 时间戳把 start_ts 写入write列（指示读取者去 start_ts 时间戳处读取数据）. 
2. 删除 lock 列时间戳为 start_ts 的内容（这里论文应该有误，给说成了 commit_ts）。

对 primary 的处理与其他 secondary 单元不同，处理 primary 的两步操作需要放到Bigtable的行事务中，而 secondary 则不需要。之所以 primary 的处理要放在行事务中，是为了避免与其他事务清理本事务的动作发生冲突，影响数据的一致性。另外，在处理 primary 的单行事务中，写入 write 列之前，要先判断 lock 列在 start_ts 处是否还存在锁，如果没有锁了，则提交失败退出。这种情况可能是本事务被其他事务给回滚了。

## 读操作 Get()
对于读操作 Get()，首先开启Bigtable行事务检查在[0, start_ts]范围内有没有锁（在快照隔离级别下，读操作对时间戳大于 start_ts 的值不感兴趣），如果有，表示另一个事务正在并发地写该单元，所以读事务必须等待直到锁释放或等待超时后执行失败处理的善后工作（见后面关于失败处理的部分）；如果没有发现锁，那么Get()在这个时间戳范围内读取write列的最新值，返回该write列值指定的时间戳位置的data值给调用者。

关于读写，一个直观的例子就是论文中给出的 Bob 向 Joe 转账的例子，另外就是论文中的伪代码。

## 失败处理

客户端如果在事务提交过程中死掉，会有锁遗留下来，Percolator必须清理这些锁，否则未来的事务无法进行。事务 A 碰到 B 遗留的锁，A 可以认为 B 已经死掉，并为 B 清理这些锁，但有时 B 其实并未死掉，只是提交的比较慢，这时A可能会误杀B。误杀没关系，但绝不能A清理和B提交互相干扰，为了让二者互不干扰，Percolator 采用锁同步的方式让这两个操作只能有一个执行。清理和提交操作都需要修改 primary lock，Bigtable的行事务可以保证 A 清理 B 的锁与B提交之间不会冲突，两个操作不会并发执行，只有一个操作会执行成功。关于 A 和 B 的协作，确保以下两点：
1. 在 B 最后执行第二阶段提交前，先开启一个单行事务（等同于对primary所在的行上锁？），检查是否仍持有 primary lock，如果持有，表示事务没有遭到他人破坏，现在可以安全地把 primary lock 删除，然后在write列以提交时间戳写入开始时间戳，然后提交这个Bigtable单行事务，至此多行分布式事务 B 已经处于已提交状态。
2. 在 A 擦除 B 的 primary lock 前，A 必须开启一个单行事务（等同于对primary所在的行上锁？），检查是否 primary lock 还在，如果在，表示 B 还没有被提交，那么 A 可以安全地擦除 primary lock。

如果客户端在事务 T 写了一个 primary write 元数据之后死掉，但仍然还有剩余的lock没有来得及清理掉，那么我们必须继续提交该事务，这在论文中称为前滚（roll forward)。

一个事务 A 在执行过程中如果碰到某个其他事务 B 写在 c 列的lock，那么它通过检查该lock所指向的 primary lock 能够区分如下两种情况：
1. 如果 primary lock 已经被替换为 write record，此时 start_ts 时间戳的 primary lock 一定不见了，且 write 列在[start_ts, ∞)范围内有一个时间戳（这个时间戳就是这个未完成事务 B 的 commit_ts）对应的值为 start_ts，那么写这个锁的事务 B 一定已经提交了，但还没有提交完，必须被继续提交。
2. 否则，即 start_ts 时间戳的 primary lock 还在，表示这个事务 B 还没有被提交，那么它应该被回滚。

对于上述第 1 种情况，也就是 A 如何继续提交遗留事务 B 的问题，A 只需以 B 的 commit_ts 时间戳先写入write列，内容为lock的时间戳（也就是事务 B 的开始时间戳start_ts)，然后再删除lock的内容即可。

对于上述第 2 种情况，事务 A 无法判断 B 的客户端是已经死掉还是活着。但因为锁的清理和事务的提交都需要同步 primary lock，所以即使 A 不分青红皂白，直接回滚 B，也不会有什么问题，只是这样会带来性能损失。为了处理这种情况，Percolator 采用一些机制来判断另一个事务的活性。比如让 worker 在 Chubby lockservice 中写一个 token 表明自己活着，当进程退出时，这个token会被自动删除（被谁删除？）。为了处理worker活着但是不工作的情况，作为一个改进的措施，在lock里设置一个时间，称之为wall time，对于一个包含太老的wall time的lock，可能会被清理，所以长时间的提交操作，为了保持活性，需要周期性地更新wall time。